---
title: "Tabula Muris: All FACS analysis"
output: html_notebook
---

# Preprocessing

Load the requisite packages and some additional helper functions.

```{r}
library(Seurat)
library(dplyr)
library(Matrix)
library(stringr)
library(readr)
library(here)
```


```{r}
FACS_files = list.files(here("00_data_ingest","facs_raw_data","FACS"), full.names = TRUE)

raw.data.list = list()
for (file in FACS_files){
  raw.data <- read.csv(file, row.names = 1)
  raw.data <- Matrix(as.matrix(raw.data), sparse = TRUE)
  raw.data.list <- append(raw.data.list, raw.data)
}

raw.data <- do.call(cbind, raw.data.list)
```

```{r}
meta.data <- read.csv(here("00_data_ingest","facs_raw_data", "metadata_FACS.csv"))

plates <- str_split(colnames(raw.data),"[.]", simplify = TRUE)[,2]

rownames(meta.data) <- meta.data$plate.barcode
cell.meta.data <- meta.data[plates,]
rownames(cell.meta.data) <- colnames(raw.data)
```

```{r}
# Find ERCC's, compute the percent ERCC, and drop them from the raw data.
erccs <- grep(pattern = "^ERCC-", x = rownames(x = raw.data), value = TRUE)
percent.ercc <- Matrix::colSums(raw.data[erccs, ])/Matrix::colSums(raw.data)
ercc.index <- grep(pattern = "^ERCC-", x = rownames(x = raw.data), value = FALSE)
raw.data <- raw.data[-ercc.index,]
```

```{r}
# Create the Seurat object with all the data
tiss <- CreateSeuratObject(raw.data = raw.data, min.cells = 5, min.genes = 5)

tiss <- AddMetaData(object = tiss, cell.meta.data)
tiss <- AddMetaData(object = tiss, percent.ercc, col.name = "percent.ercc")
# Change default name for sums of counts from nUMI to nReads
colnames(tiss@meta.data)[colnames(tiss@meta.data) == 'nUMI'] <- 'nReads'
```

```{r}
ribo.genes <- grep(pattern = "^Rp[sl][[:digit:]]", x = rownames(x = tiss@data), value = TRUE)
percent.ribo <- Matrix::colSums(tiss@raw.data[ribo.genes, ])/Matrix::colSums(tiss@raw.data)
tiss <- AddMetaData(object = tiss, metadata = percent.ribo, col.name = "percent.ribo")
```

```{r}
percent.Rn45s <- Matrix::colSums(tiss@raw.data[c('Rn45s'), ])/Matrix::colSums(tiss@raw.data)
tiss <- AddMetaData(object = tiss, metadata = percent.Rn45s, col.name = "percent.Rn45s")
```

# Analysis

A sanity check: genes per cell vs reads per cell.

```{r}
GenePlot(object = tiss, gene1 = "nReads", gene2 = "nGene", use.raw=T)
```

Filter out cells with few reads and few genes.

```{r}
tiss <- FilterCells(object = tiss, subset.names = c("nGene", "nReads"), 
    low.thresholds = c(500, 50000), high.thresholds = c(25000, 5000000))
```

Normalize the data, then regress out correlation with total reads
```{r}
tiss <- NormalizeData(object = tiss)
tiss <- ScaleData(object = tiss, vars.to.regress = c("nReads", "percent.ribo","Rn45s"))
tiss <- FindVariableGenes(object = tiss, do.plot = TRUE, x.high.cutoff = Inf, y.cutoff = 0.5)
```

Run Principal Component Analysis.
```{r}
tiss <- RunPCA(object = tiss, do.print = FALSE, pcs.compute = 40)
tiss <- ProjectPCA(object = tiss, do.print = FALSE)
```

```{r, echo=FALSE, fig.height=4, fig.width=8}
PCHeatmap(object = tiss, pc.use = 1:3, cells.use = 500, do.balanced = TRUE, label.columns = FALSE, num.genes = 8)
```

Later on (in FindClusters and TSNE) you will pick a number of principal components to use. This has the effect of keeping the major directions of variation in the data and, ideally, supressing noise. There is no correct answer to the number to use, but a decent rule of thumb is to go until the plot plateaus.

```{r}
PCElbowPlot(object = tiss, num.pc = 40)
```

Choose the number of principal components to use.
```{r}
# Set number of principal components. 
n.pcs = 40
```

The clustering is performed based on a nearest neighbors graph. Cells that have similar expression will be joined together. The Louvain algorithm looks for groups of cells with high modularity--more connections within the group than between groups. The resolution parameter determines the scale...higher resolution will give more clusters, lower resolution will give fewer.

For the top-level clustering, aim to under-cluster instead of over-cluster. It will be easy to subset groups and further analyze them below.

```{r}
# Set resolution 
res.used <- 1

tiss <- FindClusters(object = tiss, reduction.type = "pca", dims.use = 1:n.pcs, 
    resolution = res.used, print.output = 0, save.SNN = TRUE)
```

To visualize 
```{r}
# If cells are too spread out, you can raise the perplexity. If you have few cells, try a lower perplexity (but never less than 10).
tiss <- RunTSNE(object = tiss, dims.use = 1:n.pcs, seed.use = 10, perplexity=30)
```

# Add in metadata, annotations, and save.

```{r}
tiss@meta.data['cluster'] <- tiss@ident
tiss@meta.data['cell'] <- rownames(tiss@meta.data)
```

```{r}
anno = read_csv(here("00_data_ingest", "FACS_raw_data", "annotations_FACS.csv"))
anno %>% group_by(tissue, cell_ontology_class) %>% summarize(count = n())
```

```{r}
tissue_colors = read_csv(here("00_data_ingest", "tissue_colors.csv"))
```

```{r}
tiss@meta.data <- tiss@meta.data %>% 
                   left_join(anno, by = 'cell') %>%
                   left_join(tissue_colors, by = 'tissue')

rownames(tiss@meta.data) <- tiss@meta.data$cell
```

```{r}
tiss_FACS = tiss
save(tiss_FACS, file=here("00_data_ingest", "global_robj", "FACS_all.Robj"))
```
